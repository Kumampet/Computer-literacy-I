s1250050 隈本剛史　コンピュータリテラシーⅠ　課題７レポート

§1:文章を一行一単語のデータに変換する。(文章から単語を抽出する)
　　ハンドアウトよりspase2newlineとして以下のスクリプトファイルを生成
　－－－－－－ー－
　｜　s/␣␣*/\     ｜
  ｜ /g　　　　    ｜
　－－－－－－－－
　　*のアスタリスクを指定することで、␣␣*どんな空白文字の連なりを関係なしに改行するように指定できる。(どんな文字列でも当てはまるものを処理するようにすることをワイルドカードという)

　　生成後に次のコマンドを打ち込む。

　sed -f spase2newline ConstitutionOfJapan.txt > word1.txt

　　これにより、それぞれの文章の単語ごとの分割・改行が完了したうえ、確認用としてword1.txtファイルに新しく書き込んだ。

§2:A-Za-z改行を残してそれ以外を除外する。
　　数字や. ,などの記号類を除外したい。よって以下のコマンドを実行した。
　　対象ファイルは§1で新規生成したword1.txtとする。

　　　sed s/[^A-Za-z\n]//g word1.txt > word2.txt

　　^を使用することによって、[]内で指定された文字以外を除外して抽出することができる。そして、抽出した場所には何も指定しない(改行)ようにするために//を置いた。
  そして、こちらでも確認用にリダイレクト>で新しいファイル名を指定して書き込んだ。

§3:Upper case を　Lower caseに置換する。
　　trコマンドを使用して置換を行った。同様に処理対象ファイルはword2.txtとした。

　　　/usr/bin/tr "[:upper:]" "[:lower:]" < word2.txt > word3.txt

§4:アルファベット順に並び替える
　　sortコマンドを使って並び替える。同様に前工程で生成したファイルを対象とする。

　　　sort word3.txt > word4.txt
　　
　　このとき、生成したファイルの冒頭に謎の900行を超える改行が行われていたため、見ただけでは正しく生成されていないように見えた。冒頭の改行を消せば正しく処理が行われていることが確認できた。

§5:出現頻度を数える
　　出現頻度を数えるために、ハンドアウトのサンプルプログラムのうちwordcount2.awkを使用してそれぞれの単語の出現頻度を計上させた。コマンドは以下のとおりである。

　　　awk -f wordcount2.awk word4.txt

以上、全工程が問題なく終了した。

　　
